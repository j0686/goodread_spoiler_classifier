{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'eat', 'banana', '!']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import *\n",
    "from collections import defaultdict\n",
    "from math import log2\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from predeal_dataset import *\n",
    "\n",
    "DICTIONARY_SIZE = 1000\n",
    "BIGRAM_DICT_SIZE = 1200\n",
    "TRIGRAM_DICT_SIZE = 1400\n",
    "\n",
    "puncts = string.punctuation\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "tokenizer_cache = dict()\n",
    "def tokenize(sentence:str,use_stemmer:bool=True,cache=tokenizer_cache)->List[str]:\n",
    "    sentence = sentence.replace(\"(\",\"( \").replace(\"[\",\"[ \").replace(\"{\",\"{ \")\n",
    "    if cache is not None:\n",
    "        if (sentence,use_stemmer) in cache:\n",
    "            return cache[(sentence,use_stemmer)]\n",
    "    res = list()\n",
    "    tmp = sentence.split()\n",
    "    for word in tmp:\n",
    "        if len(word)==0:\n",
    "            continue\n",
    "        if word[-1] in puncts:\n",
    "            p = word[-1]\n",
    "            word = word[:-1]\n",
    "            if len(word)>0:\n",
    "                word = word.lower()\n",
    "                if use_stemmer:\n",
    "                    word = stemmer.stem(word)\n",
    "                res.append(word)\n",
    "            res.append(p)\n",
    "        else:\n",
    "            word = word.lower()\n",
    "            if use_stemmer:\n",
    "                word = stemmer.stem(word)\n",
    "            res.append(word)\n",
    "    if cache is not None:\n",
    "        cache[(sentence,use_stemmer)] = res\n",
    "    return res\n",
    "\n",
    "\n",
    "tokenize(\"I love eatting bananas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_text_to_file(text:str)->None:\n",
    "    with open(\"./output/log.txt\",\"a\") as fout:\n",
    "        fout.write(text+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoiler_dataset = sample_sub_spoiler_set(SUBSET_SENTENCE_CNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:53<00:00, 440.62it/s]\n"
     ]
    }
   ],
   "source": [
    "word_cnt = defaultdict(int)\n",
    "bigram_word_cnt = defaultdict(int)\n",
    "trigram_word_cnt = defaultdict(int)\n",
    "\n",
    "for datum in tqdm(spoiler_dataset):\n",
    "    sentence = datum['review_sentence']\n",
    "    words = tokenize(sentence)\n",
    "    for word in words:\n",
    "        word_cnt[word]+=1\n",
    "    if len(words)>=2:\n",
    "        for (word1,word2) in zip(words[:-1],words[1:]):\n",
    "            bigram_word_cnt[(word1,word2)]+=1\n",
    "    if len(words)>=3:\n",
    "        for (word1,word2,word3) in zip(words[:-2],words[1:-1],words[2:]):\n",
    "            trigram_word_cnt[(word1,word2,word3)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_with_freq = list(word_cnt.items())\n",
    "word_with_freq.sort(key=lambda tup:tup[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = word_with_freq[:DICTIONARY_SIZE]\n",
    "dictionary = list(map(lambda tup:tup[0],dictionary))\n",
    "word2id = {word:i for i,word in enumerate(dictionary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_only_feature(datum):\n",
    "    return [len(datum['review_sentence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(datum):\n",
    "    res = [0]*DICTIONARY_SIZE\n",
    "    words = tokenize(datum['review_sentence'])\n",
    "    for word in words:\n",
    "        if not word in dictionary:\n",
    "            continue\n",
    "        res[word2id[word]]+=1\n",
    "    res.append(len(words)+1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_word_with_freq = list()\n",
    "bigram_word_with_freq.extend(word_cnt.items())\n",
    "bigram_word_with_freq.extend(bigram_word_cnt.items())\n",
    "bigram_word_with_freq.sort(key=lambda tup:tup[1],reverse=True)\n",
    "bigram_dictionary = bigram_word_with_freq[:BIGRAM_DICT_SIZE]\n",
    "bigram_word2id = {word:i for i,word in enumerate(bigram_dictionary)}\n",
    "def bigram_features(datum):\n",
    "    res = [0]*DICTIONARY_SIZE\n",
    "    words = tokenize(datum['review_sentence'])\n",
    "    for word in words:\n",
    "        if not word in dictionary:\n",
    "            continue\n",
    "        res[word2id[word]]+=1\n",
    "    if len(words)>=2:\n",
    "        for bi_word in zip(words[:-1],words[1:]):\n",
    "            if not bi_word in dictionary:\n",
    "                continue\n",
    "            res[word2id[bi_word]]+=1\n",
    "    res.append(len(words)+1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_word_with_freq = list()\n",
    "trigram_word_with_freq.extend(word_cnt.items())\n",
    "trigram_word_with_freq.extend(bigram_word_cnt.items())\n",
    "trigram_word_with_freq.extend(trigram_word_cnt.items())\n",
    "trigram_word_with_freq.sort(key=lambda tup:tup[1],reverse=True)\n",
    "trigram_dictionary = trigram_word_with_freq[:TRIGRAM_DICT_SIZE]\n",
    "trigram_word2id = {word:i for i,word in enumerate(trigram_dictionary)}\n",
    "def trigram_features(datum):\n",
    "    res = [0]*DICTIONARY_SIZE\n",
    "    words = tokenize(datum['review_sentence'])\n",
    "    for word in words:\n",
    "        if not word in dictionary:\n",
    "            continue\n",
    "        res[word2id[word]]+=1\n",
    "    if len(words)>=2:\n",
    "        for bi_word in zip(words[:-1],words[1:]):\n",
    "            if not bi_word in dictionary:\n",
    "                continue\n",
    "            res[word2id[bi_word]]+=1\n",
    "    if len(words)>=3:\n",
    "        for tri_word in zip(words[:-2],words[1:-1],words[2:]):\n",
    "            if not tri_word in dictionary:\n",
    "                continue\n",
    "            res[word2id[tri_word]]+=1\n",
    "    res.append(len(words)+1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXsAndYs(spoiler_dataset:List[dict],feature_func)->Tuple[np.ndarray,np.ndarray]:\n",
    "    resX = list()\n",
    "    resY = list()\n",
    "    for datum in tqdm(spoiler_dataset):\n",
    "        resX.append(feature_func(datum))\n",
    "        resY.append(datum['label'])\n",
    "    return np.array(resX,dtype=float),np.array(resY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(spoiler_dataset)\n",
    "trainset,validset,testset = spoiler_dataset[:TRAIN_SET_CNT],spoiler_dataset[TRAIN_SET_CNT:-TEST_SET_CNT],spoiler_dataset[-TEST_SET_CNT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [01:37<00:00, 411.14it/s]\n",
      "100%|██████████| 5000/5000 [00:12<00:00, 411.26it/s]\n",
      "100%|██████████| 5000/5000 [00:12<00:00, 388.41it/s]\n"
     ]
    }
   ],
   "source": [
    "trainX,trainY = getXsAndYs(trainset,features)\n",
    "validX,validY = getXsAndYs(validset,features)\n",
    "testX,testY = getXsAndYs(testset,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight={0: 0.5357908272610373, 1: 7.485029940119761})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight={0: 0.5357908272610373, 1: 7.485029940119761})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight={0: 0.5357908272610373, 1: 7.485029940119761})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = dict(zip(np.unique(trainY), len(trainY) / (len(np.unique(trainY)) * np.bincount(trainY))))\n",
    "model = LogisticRegression(penalty='l2', C=1.0, class_weight=class_weights)\n",
    "model.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3703233614800921, 0.2989233643714776)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_best_ths_with_ber(pred_prop_with_label): \n",
    "    pred_prop_with_label.sort(reverse=True)\n",
    "    valid_set_pos_cnt = sum(tup[1] for tup in pred_prop_with_label)\n",
    "    valid_set_neg_cnt = len(pred_prop_with_label)-valid_set_pos_cnt\n",
    "    best_ths = 1.0\n",
    "    best_ber = 0.5\n",
    "    curr_false_positive = 0\n",
    "    curr_false_negative = valid_set_pos_cnt\n",
    "    for (prob,label) in pred_prop_with_label:\n",
    "        ths = prob-0.00001\n",
    "        if label==1:\n",
    "            curr_false_negative-=1\n",
    "        else:\n",
    "            curr_false_positive+=1\n",
    "        ber = 0.5*(curr_false_negative/valid_set_pos_cnt+curr_false_positive/valid_set_neg_cnt)\n",
    "        if ber<best_ber:\n",
    "            best_ber = ber\n",
    "            best_ths = ths\n",
    "    return best_ths,best_ber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "validYPred = model.predict(validX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_info(y_actual,y_predict):\n",
    "    y_actual = np.array(y_actual)\n",
    "    y_predict = np.array(y_predict)\n",
    "    y_actual = y_actual.reshape((-1,))\n",
    "    y_predict = y_predict.reshape((-1,))\n",
    "    TP = np.sum((y_actual == 1) & (y_predict == 1))\n",
    "    FP = np.sum((y_actual == 0) & (y_predict == 1))\n",
    "    TN = np.sum((y_actual == 0) & (y_predict == 0))\n",
    "    FN = np.sum((y_actual == 1) & (y_predict == 0))\n",
    "    TPR = TP / (TP + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FNR = FN / (TP + FN)\n",
    "    BER = 1 - (0.5 * (TPR + TNR))\n",
    "    accu = np.sum(y_actual==y_predict)/len(y_actual)\n",
    "    return accu,TP,FP,TN,FN,TPR, FPR, TNR, FNR, BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7742,\n",
       " 204,\n",
       " 997,\n",
       " 3667,\n",
       " 132,\n",
       " 0.6071428571428571,\n",
       " 0.21376500857632932,\n",
       " 0.7862349914236707,\n",
       " 0.39285714285714285,\n",
       " 0.3033110757167361)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_performance_info(validY,validYPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(feature_func,description:str):\n",
    "    def getXsAndYs(spoiler_dataset:List[dict])->Tuple[np.ndarray,np.ndarray]:\n",
    "        resX = list()\n",
    "        resY = list()\n",
    "        for datum in tqdm(spoiler_dataset):\n",
    "            resX.append(feature_func(datum))\n",
    "            resY.append(datum['label'])\n",
    "        return np.array(resX,dtype=float),np.array(resY)\n",
    "    random.seed(42)\n",
    "    random.shuffle(spoiler_dataset)\n",
    "    print(\"start processing dataset\")\n",
    "    trainset,validset,testset = spoiler_dataset[:TRAIN_SET_CNT],spoiler_dataset[TRAIN_SET_CNT:-TEST_SET_CNT],spoiler_dataset[-TEST_SET_CNT:]\n",
    "    trainX,trainY = getXsAndYs(trainset)\n",
    "    validX,validY = getXsAndYs(validset)\n",
    "    testX,testY = getXsAndYs(testset)\n",
    "    print(\"process dataset finished\")\n",
    "    best_model,ths,best_ber,best_c = None,0.5,0.5,0.0\n",
    "    for c in tqdm([0.1,0.15,0.2,0.25,0.35,0.5,0.7,1.0,1.4,2.0,2.8,4.0]):\n",
    "        class_weights = dict(zip(np.unique(trainY), len(trainY) / (len(np.unique(trainY)) * np.bincount(trainY))))\n",
    "        model = LogisticRegression(penalty='l2', C=c, class_weight=class_weights)\n",
    "        model.fit(trainX,trainY)\n",
    "        best_ths,ber = get_best_ths_with_ber(list(zip(map(lambda tup:tup[1],model.predict_proba(validX)),validY)))\n",
    "        if ber<best_ber:\n",
    "            best_ber = ber\n",
    "            best_model=model\n",
    "            ths = best_ths\n",
    "            best_c = c\n",
    "    prob_testset = best_model.predict_proba(testX)\n",
    "    pred_testset = list(int(prob[1]>ths) for prob in prob_testset)\n",
    "    accu,TP,FP,TN,FN,TPR, FPR, TNR, FNR, BER = get_performance_info(testY,pred_testset)\n",
    "    msg = \"%s , best_l2:%f\\n    %7s%7s%7s%7s%7s%7s%7s\\n     %.4f %.4f %.4f %.4f %.4f %.4f %.4f \"%(description,best_c,\"accu\",\"ber\",\"tpr\",\"fpr\",\"tnr\",\"fnr\",\"ths\",accu,BER,TPR,FPR,TNR,FNR,ths)\n",
    "    print(msg)\n",
    "    log_text_to_file(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [01:37<00:00, 409.34it/s]\n",
      "100%|██████████| 5000/5000 [00:12<00:00, 412.95it/s]\n",
      "100%|██████████| 5000/5000 [00:12<00:00, 407.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process dataset finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 12%|█▎        | 1/8 [00:05<00:39,  5.69s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 25%|██▌       | 2/8 [00:11<00:33,  5.62s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 38%|███▊      | 3/8 [00:16<00:27,  5.54s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 50%|█████     | 4/8 [00:21<00:21,  5.42s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 62%|██████▎   | 5/8 [00:27<00:16,  5.48s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 75%|███████▌  | 6/8 [00:31<00:10,  5.11s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 88%|████████▊ | 7/8 [00:36<00:04,  4.79s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████| 8/8 [00:39<00:00,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram bow model , best_l2:2.000000\n",
      "       accu    ber    tpr    fpr    tnr    fnr    ths\n",
      "     0.6966 0.2845 0.7370 0.3061 0.6939 0.2630 0.4173 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline(features,\"1-gram bow model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [03:08<00:00, 212.65it/s]\n",
      "100%|██████████| 5000/5000 [00:23<00:00, 213.02it/s]\n",
      "100%|██████████| 5000/5000 [00:23<00:00, 209.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process dataset finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 12%|█▎        | 1/8 [00:05<00:39,  5.65s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 25%|██▌       | 2/8 [00:11<00:33,  5.51s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 38%|███▊      | 3/8 [00:16<00:28,  5.61s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 50%|█████     | 4/8 [00:22<00:22,  5.61s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 62%|██████▎   | 5/8 [00:27<00:16,  5.59s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 75%|███████▌  | 6/8 [00:33<00:11,  5.57s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 88%|████████▊ | 7/8 [00:39<00:05,  5.58s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████| 8/8 [00:44<00:00,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-gram bow model , best_l2:0.700000\n",
      "       accu    ber    tpr    fpr    tnr    fnr    ths\n",
      "     0.7818 0.2976 0.6111 0.2064 0.7936 0.3889 0.5093 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline(bigram_features,\"bi-gram bow model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [04:39<00:00, 143.28it/s]\n",
      "100%|██████████| 5000/5000 [00:34<00:00, 143.70it/s]\n",
      "100%|██████████| 5000/5000 [00:34<00:00, 145.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process dataset finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 12%|█▎        | 1/8 [00:05<00:37,  5.34s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 25%|██▌       | 2/8 [00:11<00:33,  5.53s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 38%|███▊      | 3/8 [00:16<00:27,  5.47s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 50%|█████     | 4/8 [00:21<00:21,  5.44s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 62%|██████▎   | 5/8 [00:27<00:16,  5.39s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 75%|███████▌  | 6/8 [00:32<00:10,  5.39s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 88%|████████▊ | 7/8 [00:38<00:05,  5.47s/it]c:\\Users\\JipingZhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████| 8/8 [00:43<00:00,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tri-gram bow model , best_l2:4.000000\n",
      "       accu    ber    tpr    fpr    tnr    fnr    ths\n",
      "     0.7258 0.2874 0.6973 0.2721 0.7279 0.3027 0.4361 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline(trigram_features,\"tri-gram bow model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [00:00<00:00, 231831.97it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 1002558.56it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 1253602.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process dataset finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 17.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length only baseline , best_l2:0.350000\n",
      "       accu    ber    tpr    fpr    tnr    fnr    ths\n",
      "     0.5350 0.3628 0.7540 0.4796 0.5204 0.2460 0.4227 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline(len_only_feature,\"length only baseline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
